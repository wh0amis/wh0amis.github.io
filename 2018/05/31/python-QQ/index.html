<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      我爬取了空间说说，看看成长中的自己在说什么？ | 拥雪待春色 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="John Doe">
    
    

    <meta name="description" content="##0x01 分析　　先分析QQ空间说说页面，确定我们要爬取的内容，我要爬取的是说说内容。由于QQ空间用户巨大，不可能采用静态输出内容，很有可能是通过接口获取用户说说信息然后进行渲染输出。为了验证我们的猜想我们看下网络请求。">
<meta name="keywords" content="爬虫">
<meta property="og:type" content="article">
<meta property="og:title" content="我爬取了空间说说，看看成长中的自己在说什么？ | 拥雪待春色">
<meta property="og:url" content="http://yoursite.com/2018/05/31/python-QQ/index.html">
<meta property="og:site_name" content="拥雪待春色">
<meta property="og:description" content="##0x01 分析　　先分析QQ空间说说页面，确定我们要爬取的内容，我要爬取的是说说内容。由于QQ空间用户巨大，不可能采用静态输出内容，很有可能是通过接口获取用户说说信息然后进行渲染输出。为了验证我们的猜想我们看下网络请求。">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/1574161-2e1ebd10812bb85f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/1574161-fd9b5863d7fc4e2a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/1574161-6773b33a0f44b61a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/1574161-d84efffa1792e451.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/1574161-35a87b36ec590245.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2018-05-31T09:57:35.487Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="我爬取了空间说说，看看成长中的自己在说什么？ | 拥雪待春色">
<meta name="twitter:description" content="##0x01 分析　　先分析QQ空间说说页面，确定我们要爬取的内容，我要爬取的是说说内容。由于QQ空间用户巨大，不可能采用静态输出内容，很有可能是通过接口获取用户说说信息然后进行渲染输出。为了验证我们的猜想我们看下网络请求。">
<meta name="twitter:image" content="https://upload-images.jianshu.io/upload_images/1574161-2e1ebd10812bb85f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css">

</head>
<body>

    <span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        
        <a href="/" title="link to homepage for 拥雪待春色"><img src="/images/avatar.png" width="80" alt="拥雪待春色 logo" class="panel-cover__logo logo" /></a>
        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">拥雪待春色</a></h1>
        <hr class="panel-cover__divider" />

        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



<nav class="cover-navigation navigation--social">
  <ul class="navigation">

    
      <!-- Github -->
      <li class="navigation__item">
        <a href="https://github.com/wh0amis" title="Huno on GitHub">
          <i class='icon icon-social-github'></i>
          <span class="label">GitHub</span>
        </a>
      </li>
    

    <!-- China social icon -->
    <!--
    
      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-douban'></i>
          <span class="label">Douban</span>
        </a>
      </li>

      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-weibo'></i>
          <span class="label">Weibo</span>
        </a>
      </li>

    -->



  </ul>
</nav>



        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">我爬取了空间说说，看看成长中的自己在说什么？</h1>

    

    <div class="post-meta">
      <time datetime="2018-05-31" class="post-meta__date date">2018-05-31</time> 

      <span class="post-meta__tags tags">

          

          
             &#8226; 标签:
            <font class="tags">
              <a class="tags-link" href="/tags/爬虫/">爬虫</a>
            </font>
          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <p>##0x01 分析<br>　　先分析QQ空间说说页面，确定我们要爬取的内容，我要爬取的是说说内容。由于QQ空间用户巨大，不可能采用静态输出内容，很有可能是通过接口获取用户说说信息然后进行渲染输出。为了验证我们的猜想我们看下网络请求。<br><a id="more"></a><br><img src="https://upload-images.jianshu.io/upload_images/1574161-2e1ebd10812bb85f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="1.png"><br><img src="https://upload-images.jianshu.io/upload_images/1574161-fd9b5863d7fc4e2a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片.png"></p>
<p>##0x02 数据爬取<br>可以确定该接口即为说说接口，有了接口剩下的就好操作了，直接撸代码爬数据。接口返回的数据是JSON格式，直接解析就OK。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment">#from urlparse import urljoin</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding( <span class="string">"utf-8"</span> )</span><br><span class="line"></span><br><span class="line">csv_file = file(<span class="string">"rent.csv"</span>,<span class="string">"ab+"</span>) <span class="comment">#打开rent.csv</span></span><br><span class="line">csv_file.write(codecs.BOM_UTF8)</span><br><span class="line">csv_writer = csv.writer(csv_file, delimiter=<span class="string">','</span>) <span class="comment"># 创建writer对象，指定文件与分隔符</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_cookie</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'cookie.txt'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        cookies=&#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.read().split(<span class="string">';'</span>):</span><br><span class="line">            name,value=line.strip().split(<span class="string">'='</span>,<span class="number">1</span>)  <span class="comment">#1代表只分割一次</span></span><br><span class="line">            cookies[name]=value </span><br><span class="line">        <span class="keyword">return</span> cookies</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_row</span><span class="params">(i)</span>:</span></span><br><span class="line">	url = <span class="string">"https://h5.qzone.qq.com/proxy/domain/taotao.qq.com/cgi-bin/emotion_cgi_msglist_v6?uin=1056680519&amp;inCharset=utf-8&amp;outCharset=utf-8&amp;hostUin=1056680519&amp;notice=0&amp;sort=0&amp;pos=&#123;pos&#125;&amp;num=20&amp;cgi_host=http%3A%2F%2Ftaotao.qq.com%2Fcgi-bin%2Femotion_cgi_msglist_v6&amp;code_version=1&amp;format=jsonp&amp;need_private_comment=1&amp;g_tk=1835140580&amp;qzonetoken=79638c17978916ad05939c80583e2478e6b640717a4063ed5d0c6b4d5156fad804db82c1518aad5ff4"</span></span><br><span class="line">	response = requests.get(url.format(pos=i),cookies=get_cookie())  <span class="comment"># 抓取目标页面</span></span><br><span class="line">	text = json.loads(response.text[<span class="number">10</span>:<span class="number">-2</span>])</span><br><span class="line">	max = len(text[<span class="string">"msglist"</span>])</span><br><span class="line">	<span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>,max):</span><br><span class="line">		conlist = text[<span class="string">"msglist"</span>][x][<span class="string">"conlist"</span>]</span><br><span class="line">		created_time = text[<span class="string">"msglist"</span>][x][<span class="string">"created_time"</span>]</span><br><span class="line">		cmtnum = text[<span class="string">"msglist"</span>][x][<span class="string">"cmtnum"</span>]</span><br><span class="line">		time_local = time.localtime(created_time)</span><br><span class="line">		dt = time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>,time_local)</span><br><span class="line">		<span class="keyword">if</span> <span class="keyword">not</span> conlist:</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		con = re.search(<span class="string">"(?&lt;=con': u')(.+?)(?='&#125;)"</span>,str(conlist))</span><br><span class="line">		<span class="keyword">if</span> <span class="keyword">not</span> con:</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		<span class="keyword">print</span> con.group().decode(<span class="string">'unicode_escape'</span>)</span><br><span class="line">		csv_writer.writerow([con.group().decode(<span class="string">'unicode_escape'</span>),dt,cmtnum])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">	i = <span class="number">-20</span>;</span><br><span class="line">	<span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">		i += <span class="number">20</span></span><br><span class="line">		get_row(i)</span><br><span class="line">		<span class="keyword">print</span> i</span><br><span class="line">		<span class="keyword">if</span> i &gt;=<span class="number">2740</span>:</span><br><span class="line">			<span class="keyword">break</span></span><br></pre></td></tr></table></figure></p>
<p>将url更换成自己抓取到的地址，需要注意内部包含一个{pos},另外在根目录下建立一个cookie.txt文件，将cookie写进去。然后就可以愉快的采集数据了。<br><img src="https://upload-images.jianshu.io/upload_images/1574161-6773b33a0f44b61a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片.png"><br>跑完以后会在根目录下生成一个rent.csv的文件。里面就是采集下来的数据。</p>
<p>##0x03 制作云图</p>
<p>因为爬取出来评论数据都是字符串，所以需要对整个字符串进行分词，然后统计每个词语出现的评论。我采用 jieba 库来进行分词，采用WordCloud制作云图。代码就参考网上开源的代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">text_from_file_with_apath = open(<span class="string">'1.txt'</span>).read() <span class="comment">#1.txt为待分析处理文本</span></span><br><span class="line"></span><br><span class="line">wordlist_after_jieba = jieba.cut(text_from_file_with_apath, cut_all = <span class="keyword">True</span>)</span><br><span class="line">wl_space_split = <span class="string">" "</span>.join(wordlist_after_jieba)</span><br><span class="line"></span><br><span class="line">my_wordcloud = WordCloud().generate(wl_space_split)</span><br><span class="line"></span><br><span class="line">plt.imshow(my_wordcloud)</span><br><span class="line">plt.axis(<span class="string">"off"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>先安装相关库<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install wordcloud</span><br><span class="line">pip install jieba</span><br></pre></td></tr></table></figure></p>
<p>如果报编码错误是因为wordcloud 默认使用了DroidSansMono.ttf 字体库，改一下换成一个支持中文的ttf 字库，丢到wordcloud的目录下面并修改wordcloud.py中的第28行就可以了。</p>
<p>最后制作出来的云图效果是：<br><img src="https://upload-images.jianshu.io/upload_images/1574161-d84efffa1792e451.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="结果.png"></p>
<p> 个人感觉结果不是很符合我的气质，哈哈，应该是算法有关系。于是我又将相关数据丢到在线生成词云的网站看了看：<br><img src="https://upload-images.jianshu.io/upload_images/1574161-35a87b36ec590245.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片.png"></p>
<p>##0x04 结语<br>结合两张分析图可以看出从我的第一条说说到现在，我的心路历程，总结下来就是：<br><code>我吐槽过这牛逼的世界、也感叹过这烦忧的人生。
我说过无数的晚安、也表达过年少的相思。
我喝过无数的励志鸡汤、但也会对世界产生不安。
我有过孤独的时候，但也看过了很多风景。</code><br>看来人啊，总是在成长啊。</p>

  </section>

  <section class="post-comments">

    <!-- 将评论系统（例如Disqus、多说、友言、畅言等）提供的代码片段粘贴在这里 -->
    
</section>


</article>


            <footer class="footer">

    <span class="footer__copyright">&copy; 2014-2015. | 由<a href="https://hexo.io/">Hexo</a>强力驱动 | 主题<a href="https://github.com/someus/huno">Huno</a></span>
    
</footer>
        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    

    

    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1273829933'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s22.cnzz.com/stat.php%3Fid%3D1273829933%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

</body>
</html>
